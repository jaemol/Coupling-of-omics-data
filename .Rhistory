source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "1"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet)
# if the variance is equal to zero, then its a zero-column
#which(unname(apply(inData, 2, var))==0)
throwAway <- which(apply(inData, 2, var)==0)[]
# dropping columns by index
inData = inData[, -throwAway]
rm(throwAway) # to save memory
print("Generating metadata...")
## finding different interesting information on the set
## mean, var, STD, ratio of zeros,
meanData  <- unname(apply(inData, 2, mean))
stdData   <- unname(apply(inData, 2, sd))
varData   <- unname(apply(inData, 2, var))
ratioData <- unname(apply(inData, 2, function(x){length(which(x==0))/length(x)}))
CVData    <- unname(apply(inData, 2, function(x){sd(x)/mean(x)}))
plot(sort(meanData), main = "Mean Data")
plot(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(ratioData), main = "Singleton ratios")
plot(sort(CVData), main = "Relative standard deviation")
plot(sort(meanData), main = "Mean Data")
(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(meanData), main = "Mean Data")
plot(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(ratioData), main = "Singleton ratios")
plot(sort(CVData), main = "Relative standard deviation")
# fitting Michaelis-Menten function to data
print("Fitting Michaelis-Menten function...")
time_frame <- seq(from = 1, to = length(ratioData), by = 1)
mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
start = list(Vm=max(ratioData), K=max(time_frame) / 2))
?try
try(mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
start = list(Vm=max(ratioData), K=max(time_frame) / 2)))
try(mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
start = list(Vm=max(ratioData), K=max(time_frame) / 2)), silent = TRUE)
try(mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
start = list(Vm=max(ratioData), K=max(time_frame) / 2)), silent = TRUE, outFile = "Could not make MM model, moving on")
try(mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
start = list(Vm=max(ratioData), K=max(time_frame) / 2)), silent = TRUE, outFile = print("Could not make MM model, moving on"))
?warning
tryCatch(mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
start = list(Vm=max(ratioData), K=max(time_frame) / 2)),
warning("The Michaelis-Menten function could not be made using this data, moving on"))
# parameters estimated including confidence interval
coef(mmModel)
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "1"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet)
# tryCatch(mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
#                         start = list(Vm=max(ratioData), K=max(time_frame) / 2)),
#          warning("The Michaelis-Menten function could not be made using this data, moving on"))
mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame),
start = list(Vm=max(ratioData), K=max(time_frame) / 2))
?options
?warn
# loading NetCoMi library
library(NetCoMi)
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet)
data = inData
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
chosenWeek      <- "4"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet)
?except
source("Programming/data_filtering.R")
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "4"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet)
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "4"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet)
?try
?tryCatch
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "4"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet)
# if the variance is equal to zero, then its a zero-column
#which(unname(apply(inData, 2, var))==0)
throwAway <- which(apply(inData, 2, var)==0)[]
# dropping columns by index
inData = inData[, -throwAway]
rm(throwAway) # to save memory
View(inData)
print("Generating metadata...")
## finding different interesting information on the set
## mean, var, STD, ratio of zeros,
meanData  <- unname(apply(inData, 2, mean))
stdData   <- unname(apply(inData, 2, sd))
varData   <- unname(apply(inData, 2, var))
ratioData <- unname(apply(inData, 2, function(x){length(which(x==0))/length(x)}))
CVData    <- unname(apply(inData, 2, function(x){sd(x)/mean(x)}))
plot(sort(meanData), main = "Mean Data")
plot(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(ratioData), main = "Singleton ratios")
plot(sort(CVData), main = "Relative standard deviation")
max(ratioData)
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "4"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
chosenWeek      <- "1"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
data = inData
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
colVector <- 1:length(colnames(data))
for (i in 1:length(colVector)) {
if (i<=max(dataOneColumns)) {colVector[i] = "green"} else {colVector[i] = "red"}
}
if (chosenTaxonomy=="genus"){
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
} else {
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
}
# building single network with SPRING as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "pearson",thresh = 0.5,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
props_single_fullSet <- netAnalyze(net_single_fullSet,
centrLCC = TRUE,
clustMethod = "cluster_fast_greedy",
hubPar = "eigenvector",
weightDeg = FALSE, normDeg = FALSE)
# building single network with SPRING as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "pearson",thresh = 0.5,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
View(inData)
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "genus"
chosenWeek      <- "1"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
View(inData)
data = inData
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
colVector <- 1:length(colnames(data))
for (i in 1:length(colVector)) {
if (i<=max(dataOneColumns)) {colVector[i] = "green"} else {colVector[i] = "red"}
}
if (chosenTaxonomy=="genus"){
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
} else {
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
}
# building single network with SPRING as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "pearson",thresh = 0.5,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
which(data[data == NA])
which(data[data == "NA"])
is.na(data)
which(is.na(data)==TRUE)
data[2793]
which(is.na.data.frame(data)==TRUE)
View(data)
# loading in data
df_metab_original <- read.csv("Data/metabolomic_day7,28,70.csv", header = TRUE,
sep = ";", stringsAsFactors = FALSE, na.strings = "NA", strip.white = TRUE)
df_metab_numOnly = read.csv("Data/metabolomic_day7,28,70_NumOnly.csv", header = FALSE,
sep = ";", stringsAsFactors = FALSE, strip.white = TRUE)
# naming columns and rows
colnames(df_metab_numOnly) = colnames(df_metab_original)[-1]
rownames(df_metab_numOnly) = df_metab_original[,1][-1]
# transposing the data frame
df_metab_tmp1 = as.data.frame(t(df_metab_numOnly))
# loading in metadata metabolomics sheet - changed data to .csv first, to make it work
metadata_metabolomics  <- read.csv("Data/Metadata-metabolomics.csv", fill = TRUE, header = TRUE, sep = ";")
# fetching two first rows / names
rownam_samples_metab  <- rownames(df_metab_tmp1)
addit_info_samples    <- df_metab_original[,1]
# running through the names, matching them with phyloseq naming
metab_new_names <- rownam_samples_metab
for (i in 1:length(rownam_samples_metab)) {
num_grep = as.numeric(unlist(regmatches(rownam_samples_metab[i], gregexpr("[[:digit:]]+", rownam_samples_metab[i]))))
if (length(num_grep) == 1 && num_grep > 400) {
# find which sample is talked about
metaDataRow = which(metadata_metabolomics$Ã¯..Sample.no...MCCe. == num_grep)
# checking for TDA
if(metadata_metabolomics$System[metaDataRow]=="TDA"){tdaBin="P"}else{tdaBin="D"}
# finding biorep
biorepSample  = metadata_metabolomics$Bio.Rep[metaDataRow]
# finding time
timeSample    = metadata_metabolomics$Time[metaDataRow] / 7
# inserting into new name format
metab_new_names[i] = paste(tdaBin,biorepSample,timeSample, sep = "-")
}
}
# inserting the correct names
rownames(df_metab_tmp1) = metab_new_names
# removing the additional column with information (1)
df_metab_tmp2 = df_metab_tmp1[,-c(1)]
# finding the common test IDs, to make a full dataset
commonIDs <- intersect(sampleID.metatax, metab_new_names)
data_metab = df_metab_tmp2
data_metax = df.full.metax
# only keeping the relevant testIDs
df_metab = data_metab[metab_new_names %in% commonIDs,]
df_metax = data_metax[sampleID.metatax %in% commonIDs,]
?na.omit
is.na(df_metab_numOnly)
which(is.na(df_metab_numOnly)==TRUE)
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "1"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
inData$`1221.34326`
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
inData$`1221.34326`
View(inData)
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
inData$`1221.34326`
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
?read.csv
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
which(is.na(inData)==TRUE)
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
which(is.na(inData)==TRUE)
inData = data
# making sure no NaN are present, removing columns if TRUE
inData <- inData[,colSums(is.na(inData))<nrow(inData)]
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
rm(list=ls())
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet = "metab"
chosenTaxonomy  <- "species"
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
chosenWeek      <- "1"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
data = inData
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
colVector <- 1:length(colnames(data))
for (i in 1:length(colVector)) {
if (i<=max(dataOneColumns)) {colVector[i] = "green"} else {colVector[i] = "red"}
}
if (chosenTaxonomy=="genus"){
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
} else {
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
}
# building single network with SPRING as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "pearson",thresh = 0.5,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
props_single_fullSet <- netAnalyze(net_single_fullSet,
centrLCC = TRUE,
clustMethod = "cluster_fast_greedy",
hubPar = "eigenvector",
weightDeg = FALSE, normDeg = FALSE)
View(net_single_fullSet)
# building single network with SPRING as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "spearman",thresh = 0.5,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
props_single_fullSet <- netAnalyze(net_single_fullSet,
centrLCC = TRUE,
clustMethod = "cluster_fast_greedy",
hubPar = "eigenvector",
weightDeg = FALSE, normDeg = FALSE)
chosenWeek      <- "null"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
data = inData
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
colVector <- 1:length(colnames(data))
for (i in 1:length(colVector)) {
if (i<=max(dataOneColumns)) {colVector[i] = "green"} else {colVector[i] = "red"}
}
if (chosenTaxonomy=="genus"){
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
} else {
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
}
# building single network with SPRING as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "spearman",thresh = 0.5,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
props_single_fullSet <- netAnalyze(net_single_fullSet,
centrLCC = TRUE,
clustMethod = "cluster_fast_greedy",
hubPar = "eigenvector",
weightDeg = FALSE, normDeg = FALSE)
?netAnalyze
View(props_single_fullSet)
#?summary.microNetProps
summary(props_single_fullSet, numbNodes = 5L)
chosenWeek      <- "10"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy)
# filtering data
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek)
data = inData
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
View(data)
colVector <- 1:length(colnames(data))
for (i in 1:length(colVector)) {
if (i<=max(dataOneColumns)) {colVector[i] = "green"} else {colVector[i] = "red"}
}
if (chosenTaxonomy=="genus"){
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
} else {
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
}
# building single network with SPRING as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "spearman",thresh = 0.5,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
props_single_fullSet <- netAnalyze(net_single_fullSet,
centrLCC = TRUE,
clustMethod = "cluster_fast_greedy",
hubPar = "eigenvector",
weightDeg = FALSE, normDeg = FALSE)
