# The sample IDs
sampleID.metatax    <- data_phys_original@sam_data$sample.name
## setting up dataframe similar to Katrines
df.fulldata.metax <- as.data.frame(t(df.otu.metatax))
rownames(df.fulldata.metax) = sampleID.metatax
# making string array with colnames
colnames_array_metatax <- str_c("DATA.",str_replace_na(df.tax.metatax$domain, replacement="NA"),"_",
str_replace_na(df.tax.metatax$phylum,  replacement="NA"),"_",
str_replace_na(df.tax.metatax$class,   replacement="NA"),"_",
str_replace_na(df.tax.metatax$order,   replacement="NA"),"_",
str_replace_na(df.tax.metatax$family,  replacement="NA"),"_",
str_replace_na(df.tax.metatax$genus,   replacement="NA"),"_",
str_replace_na(df.tax.metatax$species, replacement="NA"))
colnames(df.fulldata.metax) = colnames_array_metatax
# saving information on phaeobacter presence
array.phaebac.bin <- data_phys_original@sam_data$phaeobacter
# moving up to genus level or staying at species
if (whichTaxLevel=="genus") {
# moving up in taxonomy for the 16s data, going from species to genus
origNames <- colnames(df.fulldata.metax)
newNames <- apply(str_split_fixed(string = origNames, pattern = "[_]",7)[,1:6],1, paste, collapse="_")
length(unique(newNames))
uniqNames=unique(newNames)
newDat=data.frame(dummy=1:NROW(df.fulldata.metax))
#j=uniqNames[1]
for(j in uniqNames) {
jIndx=grep(j,origNames )
if(length(jIndx)>1) {
newDat=cbind(newDat,rowSums(df.fulldata.metax[,jIndx]))
} else {
newDat=cbind(newDat,(df.fulldata.metax[,jIndx]))
}
}
newDat=newDat[,-1]
colnames(newDat)=uniqNames
# now making that new data into 16s data set
df.fulldata.metax = newDat
}
#df.full.metax <- cbind(array.phaebac.bin,df.fulldata.metax)
df.full.metax <- df.fulldata.metax
# loading in data
df_metab_original <- read.csv("Data/allData_LCMS_metabolomics.csv", header = FALSE,
sep = ";", stringsAsFactors = FALSE, strip.white = TRUE, skip = 1)
colnames(df_metab_original) = read.csv("Data/allData_LCMS_metabolomics.csv", header = F,
sep = ";", stringsAsFactors = FALSE, strip.white = TRUE, nrows = 1)
rownames(df_metab_original) = read.csv("Data/allData_LCMS_metabolomics.csv", header = F,
sep = ";", stringsAsFactors = FALSE, strip.white = TRUE)[-1,1]
# removing first column (masses)
df_metab_original = df_metab_original[,-1]
# transposing the data frame
df_metab_tmp1 = as.data.frame(t(df_metab_original))
# loading in metadata metabolomics sheet - changed data to .csv first, to make it work
metadata_metabolomics  <- read.csv("Data/Metadata-metabolomics.csv", fill = TRUE, header = TRUE, sep = ";")
# fetching first row
rownam_samples_metab  <- rownames(df_metab_tmp1)
# running through the names, matching them with phyloseq naming
metab_new_names <- rownam_samples_metab
for (i in 1:length(rownam_samples_metab)) {
num_grep = as.numeric(unlist(regmatches(rownam_samples_metab[i], gregexpr("[[:digit:]]+", rownam_samples_metab[i]))))
#if (length(num_grep) == 1 && num_grep > 400) {
# find which sample is talked about
metaDataRow = which(metadata_metabolomics$ï..Sample.no...MCCe. == num_grep)
# ensuring no medium control (blank samples)
#if (!(num_grep==449||num_grep==458)){
# checking for TDA or control
if(metadata_metabolomics$System[metaDataRow]=="TDA"){
tdaBin="P"
} else if (metadata_metabolomics$System[metaDataRow]=="NoTDA"){
tdaBin="D"
} else {tdaBin="C"}
# finding biorep
biorepSample  = metadata_metabolomics$Bio.Rep[metaDataRow]
# finding time
timeSample    = metadata_metabolomics$Time[metaDataRow] / 7
# inserting into new name format
metab_new_names[i] = paste(tdaBin,biorepSample,timeSample, sep = "-")
#}
}
# removing samples with NA
#whichNaNRemove  <- which(gsub("MCCe", x = metab_new_names, replacement = "", perl = TRUE)==TRUE)
whichNaNRemove  <- c(1,10)
metab_new_names <- metab_new_names[-whichNaNRemove]
df_metab_tmp2   <- df_metab_tmp1[-whichNaNRemove,]
# inserting the correct names
rownames(df_metab_tmp2) = metab_new_names
# finding the common test IDs, to make a full dataset
commonIDs <- intersect(sampleID.metatax, metab_new_names)
# removing all features with masses <= 200 m/Z (mass over charge)
metabFeatToDrop <- which(as.numeric(colnames(df_metab_tmp2)) <= cutOffMetabMass)
df_metab_tmp3   <- subset(df_metab_tmp2, select = -c(metabFeatToDrop))
data_metab = df_metab_tmp3
data_metax = df.full.metax
commonIDs
sort(commonIDs)
whichWeek="null"
whichTaxLevel="species"
cutOffMetabMass=200
whichNormalization="median"
# loading data
#data_phys_original  <- readRDS("Data/allDataMetataxonomicNCLTEE.rds")
load("Data/allData_16S_NCLTEE_Reduced.RData")
data_phys_original <- ps.new
# The actual data
df.otu.metatax      <- as.data.frame(data_phys_original@otu_table)
# The results / variables
df.tax.metatax      <- as.data.frame(data_phys_original@tax_table)
# The sample IDs
sampleID.metatax    <- data_phys_original@sam_data$sample.name
## setting up dataframe similar to Katrines
df.fulldata.metax <- as.data.frame(t(df.otu.metatax))
rownames(df.fulldata.metax) = sampleID.metatax
# making string array with colnames
colnames_array_metatax <- str_c("DATA.",str_replace_na(df.tax.metatax$domain, replacement="NA"),"_",
str_replace_na(df.tax.metatax$phylum,  replacement="NA"),"_",
str_replace_na(df.tax.metatax$class,   replacement="NA"),"_",
str_replace_na(df.tax.metatax$order,   replacement="NA"),"_",
str_replace_na(df.tax.metatax$family,  replacement="NA"),"_",
str_replace_na(df.tax.metatax$genus,   replacement="NA"),"_",
str_replace_na(df.tax.metatax$species, replacement="NA"))
colnames(df.fulldata.metax) = colnames_array_metatax
# saving information on phaeobacter presence
array.phaebac.bin <- data_phys_original@sam_data$phaeobacter
# moving up to genus level or staying at species
if (whichTaxLevel=="genus") {
# moving up in taxonomy for the 16s data, going from species to genus
origNames <- colnames(df.fulldata.metax)
newNames <- apply(str_split_fixed(string = origNames, pattern = "[_]",7)[,1:6],1, paste, collapse="_")
length(unique(newNames))
uniqNames=unique(newNames)
newDat=data.frame(dummy=1:NROW(df.fulldata.metax))
#j=uniqNames[1]
for(j in uniqNames) {
jIndx=grep(j,origNames )
if(length(jIndx)>1) {
newDat=cbind(newDat,rowSums(df.fulldata.metax[,jIndx]))
} else {
newDat=cbind(newDat,(df.fulldata.metax[,jIndx]))
}
}
newDat=newDat[,-1]
colnames(newDat)=uniqNames
# now making that new data into 16s data set
df.fulldata.metax = newDat
}
#df.full.metax <- cbind(array.phaebac.bin,df.fulldata.metax)
df.full.metax <- df.fulldata.metax
# loading in data
df_metab_original <- read.csv("Data/allData_LCMS_metabolomics.csv", header = FALSE,
sep = ";", stringsAsFactors = FALSE, strip.white = TRUE, skip = 1)
colnames(df_metab_original) = read.csv("Data/allData_LCMS_metabolomics.csv", header = F,
sep = ";", stringsAsFactors = FALSE, strip.white = TRUE, nrows = 1)
rownames(df_metab_original) = read.csv("Data/allData_LCMS_metabolomics.csv", header = F,
sep = ";", stringsAsFactors = FALSE, strip.white = TRUE)[-1,1]
# removing first column (masses)
df_metab_original = df_metab_original[,-1]
# transposing the data frame
df_metab_tmp1 = as.data.frame(t(df_metab_original))
# loading in metadata metabolomics sheet - changed data to .csv first, to make it work
metadata_metabolomics  <- read.csv("Data/Metadata-metabolomics.csv", fill = TRUE, header = TRUE, sep = ";")
# fetching first row
rownam_samples_metab  <- rownames(df_metab_tmp1)
# running through the names, matching them with phyloseq naming
metab_new_names <- rownam_samples_metab
for (i in 1:length(rownam_samples_metab)) {
num_grep = as.numeric(unlist(regmatches(rownam_samples_metab[i], gregexpr("[[:digit:]]+", rownam_samples_metab[i]))))
#if (length(num_grep) == 1 && num_grep > 400) {
# find which sample is talked about
metaDataRow = which(metadata_metabolomics$ï..Sample.no...MCCe. == num_grep)
# ensuring no medium control (blank samples)
#if (!(num_grep==449||num_grep==458)){
# checking for TDA or control
if(metadata_metabolomics$System[metaDataRow]=="TDA"){
tdaBin="P"
} else if (metadata_metabolomics$System[metaDataRow]=="NoTDA"){
tdaBin="D"
} else {tdaBin="C"}
# finding biorep
biorepSample  = metadata_metabolomics$Bio.Rep[metaDataRow]
# finding time
timeSample    = metadata_metabolomics$Time[metaDataRow] / 7
# inserting into new name format
metab_new_names[i] = paste(tdaBin,biorepSample,timeSample, sep = "-")
#}
}
# inserting the correct names
rownames(df_metab_tmp2) = metab_new_names
# finding the common test IDs, to make a full dataset
commonIDs <- intersect(sampleID.metatax, metab_new_names)
# finding the common test IDs, to make a full dataset
commonIDs <- intersect(sampleID.metatax, metab_new_names)
data_phys_original@sam_data$sample.name
sortdata_phys_original@sam_data$sample.name)
sort(data_phys_original@sam_data$sample.name)
# inserting the correct names
rownames(df_metab_tmp1) = metab_new_names
# removing samples with NA
#whichNaNRemove  <- which(gsub("MCCe", x = metab_new_names, replacement = "", perl = TRUE)==TRUE)
whichNaNRemove  <- c(1,10)
metab_new_names <- metab_new_names[-whichNaNRemove]
df_metab_tmp2   <- df_metab_tmp1[-whichNaNRemove,]
View(metadata_metabolomics)
length(which(metadata_metabolomics$System=="Control"))
length(which(data_phys_original@sam_data$type=="Control"))
View(data_phys_original)
length(which(data_phys_original@sam_data$exp.condition=="Control"))
length(rownam_samples_metab)
# fetching first row
rownam_samples_metab  <- rownames(df_metab_tmp1)
# running through the names, matching them with phyloseq naming
metab_new_names <- rownam_samples_metab
for (i in 1:length(rownam_samples_metab)) {
num_grep = as.numeric(unlist(regmatches(rownam_samples_metab[i], gregexpr("[[:digit:]]+", rownam_samples_metab[i]))))
#if (length(num_grep) == 1 && num_grep > 400) {
# find which sample is talked about
metaDataRow = which(metadata_metabolomics$ï..Sample.no...MCCe. == num_grep)
# ensuring no medium control (blank samples)
#if (!(num_grep==449||num_grep==458)){
# checking for TDA or control
if(metadata_metabolomics$System[metaDataRow]=="TDA"){
tdaBin="P"
} else if (metadata_metabolomics$System[metaDataRow]=="NoTDA"){
tdaBin="D"
} else {tdaBin="C"}
# finding biorep
biorepSample  = metadata_metabolomics$Bio.Rep[metaDataRow]
# finding time
timeSample    = metadata_metabolomics$Time[metaDataRow] / 7
# inserting into new name format
metab_new_names[i] = paste(tdaBin,biorepSample,timeSample, sep = "-")
#}
}
metab_new_names
sort(metab_new_names)
rm(list=ls())
# loading NetCoMi library
library(NetCoMi)
# loading functions
source("Programming/extracting_data_NATH.R")
source("Programming/data_filtering.R")
# loading data
chosenDataSet       = "metab"       # "metab" or "genom"
chosenTaxonomy      <- "species"    # "species" or "genus"
chosenWeek          <- "null"       # "1", "4", or "10"
chosenCutoffMass    <- 200          # arbitrary value, removing based on column name
chosenNormalization <- "median"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy,
cutOffMetabMass=chosenCutoffMass, whichNormalization=chosenNormalization)
# filtering data
chosenCutoffFiltering <- 0.9
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek, cutOffOrAuto=chosenCutoffFiltering)
chosenNormalization <- "peak"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy,
cutOffMetabMass=chosenCutoffMass, whichNormalization=chosenNormalization)
# filtering data
chosenCutoffFiltering <- 0.9
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek, cutOffOrAuto=chosenCutoffFiltering)
# can only select week number 1, 4, 6, or 10
choiceOfWeekHere <- "null"
if (choiceOfWeekHere != "null") {
data = inData[gsub(".+-(?=\\d+$)", "", rownames(inData), perl = TRUE)==choiceOfWeekHere,]
} else {
data = inData
}
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
colVector <- 1:length(colnames(data))
for (i in 1:length(colVector)) {
if (i<=max(dataOneColumns)) {colVector[i] = "green"} else {colVector[i] = "red"}
}
if (chosenTaxonomy=="genus"){
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
} else {
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
}
############################
# building single network with spearman as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "spearman",thresh = 0.65,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
props_single_fullSet <- netAnalyze(net_single_fullSet,
centrLCC = TRUE,
clustMethod = "cluster_fast_greedy",
hubPar = "eigenvector",
weightDeg = FALSE, normDeg = FALSE)
#?summary.microNetProps
summary(props_single_fullSet, numbNodes = 5L)
plot(props_single_fullSet,
labelScale = F,
shortenLabels = "none",
#nodeFilter = "clustMin",
#nodeFilter = "highestBetween",
#nodeFilterPar = 50,
cexLabels = 1.3,
title1 = paste("Single network with Spearman\nWeek:", choiceOfWeekHere, "taxonomy:", chosenTaxonomy),
#title1 = "Single network with Spearman",
showTitle = T,
cexTitle = 1.7)
plot.microNetProps
plot(props_single_fullSet,
labelScale = F,
shortenLabels = "none",
#nodeFilter = "clustMin",
nodeFilter = "highestBetween",
nodeFilterPar = 50,
cexLabels = 1.3,
title1 = paste("Single network with Spearman\nWeek:", choiceOfWeekHere, "taxonomy:", chosenTaxonomy),
#title1 = "Single network with Spearman",
showTitle = T,
cexTitle = 1.7)
chosenCutoffMass    <- 500          # arbitrary value, removing based on column name
chosenNormalization <- "peak"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy,
cutOffMetabMass=chosenCutoffMass, whichNormalization=chosenNormalization)
chosenCutoffMass    <- 400          # arbitrary value, removing based on column name
chosenNormalization <- "peak"
inData <- extracting_data_NATH(whichWeek=chosenWeek, whichTaxLevel=chosenTaxonomy,
cutOffMetabMass=chosenCutoffMass, whichNormalization=chosenNormalization)
# filtering data
chosenCutoffFiltering <- 0.9
inData <- data_filtering(data=inData, whichDataSet=chosenDataSet, whichWeek=chosenWeek, cutOffOrAuto=chosenCutoffFiltering)
# can only select week number 1, 4, 6, or 10
choiceOfWeekHere <- "null"
if (choiceOfWeekHere != "null") {
data = inData[gsub(".+-(?=\\d+$)", "", rownames(inData), perl = TRUE)==choiceOfWeekHere,]
} else {
data = inData
}
dataOneColumns <- grep(x = colnames(data), pattern = "DATA.*")
colVector <- 1:length(colnames(data))
for (i in 1:length(colVector)) {
if (i<=max(dataOneColumns)) {colVector[i] = "green"} else {colVector[i] = "red"}
}
if (chosenTaxonomy=="genus"){
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)","\\1",colnames(data))
} else {
colnames(data)=gsub("DATA.Bacteria_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
colnames(data)=gsub("DATA.Archaea_[A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.][A-Za-z]*[_.](.*)[_.](.*)","\\1",colnames(data))
}
############################
# building single network with spearman as association measure - Full dataset, both treated and untreated
net_single_fullSet <- netConstruct((data),
#filtTax = "highestFreq",
#filtTaxPar = list(highestFreq = 100),
#filtSamp = "totalReads",
#filtSampPar = list(totalReads = 1000),
measure = "spearman",thresh = 0.65,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3,weighted = T,
seed = 123456)
props_single_fullSet <- netAnalyze(net_single_fullSet,
centrLCC = TRUE,
clustMethod = "cluster_fast_greedy",
hubPar = "eigenvector",
weightDeg = FALSE, normDeg = FALSE)
#?summary.microNetProps
summary(props_single_fullSet, numbNodes = 5L)
plot(props_single_fullSet,
labelScale = F,
shortenLabels = "none",
#nodeFilter = "clustMin",
nodeFilter = "highestBetween",
nodeFilterPar = 50,
cexLabels = 1.3,
title1 = paste("Single network with Spearman\nWeek:", choiceOfWeekHere, "taxonomy:", chosenTaxonomy),
#title1 = "Single network with Spearman",
showTitle = T,
cexTitle = 1.7)
plot(props_single_fullSet,
labelScale = F,
shortenLabels = "none",
#nodeFilter = "clustMin",
#nodeFilter = "highestBetween",
#nodeFilterPar = 50,
cexLabels = 1.3,
title1 = paste("Single network with Spearman\nWeek:", choiceOfWeekHere, "taxonomy:", chosenTaxonomy),
#title1 = "Single network with Spearman",
showTitle = T,
cexTitle = 1.7)
############################
# compare two networks differentiated upon presence of TDA or not
# splitting the data set of all weeks into three; TDA, noTDA and control
data_TDA      <- data[substr(rownames(data), 1, 1) == "D",]
data_noTDA    <- data[substr(rownames(data), 1, 1) == "P",]
data_control  <- data[substr(rownames(data), 1, 1) == "C",]
# Network construction
net_TDA <- netConstruct(data = data_noTDA,
data2 = data_TDA,
filtTax = "highestVar",
filtTaxPar = list(highestVar = 50),
measure = "spearman", thresh = 0.65,
measurePar = list(nlambda=10,
rep.num=10),
normMethod = "none",
zeroMethod = "none",
sparsMethod = "threshold",
dissFunc = "signed",
verbose = 3, weighted = T,
seed = 123456)
props_TDA <- netAnalyze(net_TDA,
centrLCC = FALSE,
avDissIgnoreInf = TRUE,
sPathNorm = FALSE,
clustMethod = "cluster_fast_greedy",
#hubPar = c("degree", "between", "closeness"),
hubPar = "eigenvector",
hubQuant = 0.9,
lnormFit = TRUE,
normDeg = FALSE,
normBetw = FALSE,
normClose = FALSE,
normEigen = FALSE)
summary(props_TDA)
plot(props_TDA,
sameLayout = TRUE,
nodeColor = "cluster",
nodeSize = "mclr",
labelScale = FALSE,
shortenLabels = "none",
cexNodes = 1.5,
cexLabels = 1.3,
cexHubLabels = 1,
cexTitle = 3.7,
groupNames = c("No TDA", "TDA"),
hubBorderCol  = "gray40")
source("Programming/data_analyze.R")
#####
# trying data_analyze
# henriciella + 770.4851152
data_analyze(data = inData, feature1 = "Henriciella", feature2 = "770.4851152")
source("Programming/data_analyze.R")
#####
# trying data_analyze
# henriciella + 770.4851152
data_analyze(data = inData, feature1 = "Henriciella", feature2 = "770.4851152")
feature1 = "Henriciella"
feature2 = "770.4851152"
data = inData
# finding the correct features from the data set
feat1 = data[which(stringr::str_split_fixed(string = colnames(data),
pattern = "[_]",7)==feature1, arr.ind = TRUE)[1]]
feat2 = data[which(stringr::str_split_fixed(string = colnames(data),
pattern = "[_]",7)==feature2, arr.ind = TRUE)[1]]
View(feat2)
View(feat1)
if (sampleRemovalOutliers != "null" && length(sampleRemovalOutliers)>0) {
feat1 = feat1[-sampleRemovalOutliers,]
feat2 = feat2[-sampleRemovalOutliers,]
}
sampleRemovalOutliers="null"
if (sampleRemovalOutliers != "null" && length(sampleRemovalOutliers)>0) {
feat1 = feat1[-sampleRemovalOutliers,]
feat2 = feat2[-sampleRemovalOutliers,]
}
# finding the results and printing them out
paste("Generating results for features", feature1, "and", feature2,"\n")
paste("The ordinal spearman correlation is:", cor(feat1, feat2, method = "spear"))
paste("The log1p spearman correlation is:", cor(log1p(feat1), log1p(feat2), method = "spear"))
paste("The ordinal pearson correlation is:", cor(feat1, feat2, method = "pear"))
paste("The log1p pearson correlation is:", cor(log1p(feat1), log1p(feat2), method = "pear"))
print("Plotting the correlation between the two features\n")
print("Building a linear model between the two features")
LM = lm(log1p(feat1)~log1p(feat2))
#LM = lm(log1p(feat1)~log1p(feat2))
LM = lm(feat1~feat2)
=LM
?LM
??LM
?lm
plot(feat1 ~ feat2, title(main = paste(feat1, "versus", feat2)))
plot(feat1 ~ feat2, title(main = paste(feature1, "versus", feature2)))
plot(unlist(feat1) ~ unlist(feat2), title(main = paste(feature1, "versus", feature2)))
plot(unlist(feat1) ~ unlist(feat2), ylab = feature1, xlab = feature2,
title(main = paste(feature1, "versus", feature2)))
# finding the results and printing them out
paste("Generating results for features", feature1, "and", feature2,"\n")
paste("The ordinal spearman correlation is:", cor(feat1, feat2, method = "spear"))
paste("The log1p spearman correlation is:", cor(log1p(feat1), log1p(feat2), method = "spear"))
paste("The ordinal pearson correlation is:", cor(feat1, feat2, method = "pear"))
paste("The log1p pearson correlation is:", cor(log1p(feat1), log1p(feat2), method = "pear"))
print("Plotting the correlation between the two features\n")
plot(unlist(feat1) ~ unlist(feat2), ylab = feature1, xlab = feature2,
title(main = paste(feature1, "versus", feature2)))
print("Building a linear model between the two features")
LM = lm(log1p(unlist(feat1))~log1p(unlist(feat2)))
#LM = lm(feat1~feat2)
summary(LM)
print("Plotting the related plots to the linear model")
plot(LM)
LM = lm(log1p(unlist(feat1))~log1p(unlist(feat2)), coefficients = c(feature1,feature2))
LM = lm(log1p(unlist(feat1))~log1p(unlist(feat2)), data = c(feature1,feature2))
LM = lm(unlist(feat1)~unlist(feat2))
summary(LM)
print("Plotting the related plots to the linear model")
plot(LM)
