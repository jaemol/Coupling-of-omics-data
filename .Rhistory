# negative correlated variables point to opposite sides of the plot
fviz_pca_var(pcaModel,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = FALSE     # Avoid text overlapping
)
size(inData)
length(inData[1:])
length(inData)
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
names(inData[364])
inData[364]
inData
# making PCA model
pcaModel <- prcomp(inData, scale = TRUE)
# making scree plot, to visualize eigenvalues
fviz_eig(pcaModel)
# making a graph of the variables
# visualizing the correlation between the variables
# positive correlated variables point to the same side of the plot
# negative correlated variables point to opposite sides of the plot
fviz_pca_var(pcaModel,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = FALSE     # Avoid text overlapping
)
# transposing data; samples on columns, features on rows
inData = t(inData)
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
install.packages("data.table")
library(data.table) # used to keep structure of data frame when transposing
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
# transposing data; samples on columns, features on rows
inData = t(inData)
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
# transposing data; samples on columns, features on rows
inData = transpose(inData)
# making PCA model
pcaModel <- prcomp(inData, scale = TRUE)
# making scree plot, to visualize eigenvalues
fviz_eig(pcaModel)
# making a graph of the variables
# visualizing the correlation between the variables
# positive correlated variables point to the same side of the plot
# negative correlated variables point to opposite sides of the plot
fviz_pca_var(pcaModel,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = FALSE     # Avoid text overlapping
)
inData[2:]
inData(2:)
inData[2]
inData[2,]
data[2,]
colnames(data[2])
colnames(data[3])
colnames(inData[1])
colnames(inData[2])
colnames(inData[3])
colnames(inData[4])
colnames(inData[,])
rownames(inData[1])
rownames(inData)
rownames(inData) <- colnames(data[-(1,2)])
rownames(inData) <- colnames(data[-(1:2)])
rownames(inData[1])
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
# transposing data; samples on columns, features on rows
inData = transpose(inData)
# adding the names to the transposed data
rownames(inData) <- colnames(data[-(1:2)])
# making PCA model
pcaModel <- prcomp(inData, scale = TRUE)
# making scree plot, to visualize eigenvalues
fviz_eig(pcaModel)
# making a graph of the variables
# visualizing the correlation between the variables
# positive correlated variables point to the same side of the plot
# negative correlated variables point to opposite sides of the plot
fviz_pca_var(pcaModel,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = FALSE     # Avoid text overlapping
)
# making a graph of the variables
# visualizing the correlation between the variables
# positive correlated variables point to the same side of the plot
# negative correlated variables point to opposite sides of the plot
fviz_pca_var(pcaModel,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = FALSE,     # Avoid text overlapping
select.var = list(name = rownames(inData))
)
rownames(inData[364])
rownames(inData[364,1])
# making a graph of the variables
# visualizing the correlation between the variables
# positive correlated variables point to the same side of the plot
# negative correlated variables point to opposite sides of the plot
fviz_pca_var(pcaModel,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = FALSE     # Avoid text overlapping
#,select.var = list(name = rownames(inData))
)
rm(list=setdiff(ls(), "data"))
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
testID  <- inData$testID
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$testID
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
### DBScan density-based spatial clustering ###
set.seed(123)
# excluding testID and OUA (antibiotics used or not)
inData = data
testID  <- inData$testID
OUA     <- inData$OUA
inData = subset(inData, select = -c(testID, OUA))
kmeans_model <- kmeans(inData, 5, nstart = 25)
fviz_cluster(kmeans_model, inData, frame = FALSE, geom = "point")
kmeans_model <- kmeans(inData, 7, nstart = 25)
fviz_cluster(kmeans_model, inData, frame = FALSE, geom = "point")
install.packages("fpc")
install.packages("dbscan")
# loading libraries
library(fpc)
library(dbscan)
library(factoextra)
891*109
### This is the main programming script for handling the data ###
rm(list = ls())
# loading libraries
#library(dplyr)
library(gsubfn)
## Stationary
source("Programming/extracting_data_KAT.R")
source("Programming/data_filtering.R")
# loading in the data
list[data, len_16s, len_qpcr] <- extracting_data_KAT()
data <- data_filtering(data)
View(data)
data_qpcr <- read.table("Testdata/allData_qPCR_cleaned.txt")
View(data_qpcr)
data_qpcr  <- subset(data_qpcr, select = -c(PIG, DATE, WEANING_TIME, GROUP, Newlytreated,
WEEK, SAMPLEWEEK, Florkem, Metacam, Zactran,
Antibiotic, Treatment_group, Treatment_date, CorrectedGroup, sample))
data_16s  <- read.table("Testdata/allData_16S_cleaned.txt")
# next, include only testID (PIG_DATE), OUA and the results of the analyses
data_16s   <- subset(data_16s, select = -c(PIG, DATE, WEANING_TIME, GROUP, Newlytreated,
WEEK, SAMPLEWEEK, Florkem, Metacam, Zactran,
Antibiotic, Treatment_group, Treatment_date, CorrectedGroup,
PIG.1, DATE.1, OUA.1, PIG_DATE.1, OriginalNAME))
colnames(data[100:111])
colnames(data[80:111])
### This is the main programming script for handling the data ###
rm(list = ls())
# loading libraries
#library(dplyr)
library(gsubfn)
## Stationary
source("Programming/extracting_data_KAT.R")
source("Programming/data_filtering.R")
# loading in the data
list[data, len_16s, len_qpcr] <- extracting_data_KAT()
# Loading libraries
#library(ggplot2)
library(gsubfn)
# Gonna write it out first, then make it into a function
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(PIG_DATE, OUA))
# if the variance is equal to zero, then its a zero-column
#which(unname(apply(inData, 2, var))==0)
throwAway <- which(apply(inData, 2, var)==0)[]
# dropping columns by index
inData = inData[, -throwAway]
rm(throwAway) # to save memory
print("Generating metadata...")
## finding different interesting information on the set
## mean, var, STD, ratio of zeros,
meanData  <- unname(apply(inData, 2, mean))
stdData   <- unname(apply(inData, 2, sd))
varData   <- unname(apply(inData, 2, var))
ratioData <- unname(apply(inData, 2, function(x){length(which(x==0))/length(x)}))
CVData    <- unname(apply(inData, 2, function(x){sd(x)/mean(x)}))
plot(sort(meanData), main = "Mean Data")
plot(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(ratioData), main = "Singleton ratios")
plot(sort(CVData), main = "Relative standard deviation")
# fitting Michaelis-Menten function to data
print("Fitting Michaelis-Menten function...")
time_frame <- seq(from = 1, to = length(ratioData), by = 1)
mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame), start = list(Vm=max(ratioData), K=max(time_frame) / 2))
# parameters estimated including confidence interval
coef(mmModel)
confint(mmModel, level = 0.9)
# defining to estimated parameters
Vmax = coef(mmModel)[[1]]
K    = coef(mmModel)[[2]]
# visualizing the model in relation to ratio Data
plot(sort(ratioData) ~ time_frame, col = "grey")
lines(predict(mmModel) ~ time_frame, lwd = 3, col = "dark red")
# finding local maxima, potentiel knee points
kneePoints_collected <- which(diff(sign(diff(ratioData)))==-2)+1
# finding the linear fit from origo to asymptote
a_linearFit <- max(ratioData) / max(time_frame)
b_linearFit <- min(ratioData) - a_linearFit*min(time_frame)
# using distance formular on all knee points to line
# distance formula: d = abs(a*x+b-y)/sqrt(a^2+1)
longest_distance  <- 0
longest_x         <- 0
for (i in kneePoints_collected) {
temp_x = i
temp_y = Vmax*temp_x / (K*temp_x)
dist = abs(a_linearFit*temp_x + b_linearFit-temp_y)/sqrt(a_linearFit^2+1)
if (dist >= longest_distance) {longest_distance = dist; longest_x = temp_x}
}
# defining the cutoff threshold
threshold_ratio <- ratioData[longest_x]
# if the ratioData is above the found cutoff, it is to be removed
keepIn <- which(ratioData <= threshold_ratio)
abline(h = 0.51111)
a_linearFit
b_linearFit
abline(a = b_linearFit, b=a_linearFit)
# using distance formular on all knee points to line
# distance formula: d = abs(a*x+b-y)/sqrt(a^2+1)
longest_distance  <- 0
longest_x         <- 0
kneePoints_collected
i=kneePoints_collected[1]
temp_x = i
temp_y = Vmax*temp_x / (K*temp_x)
temp_x
points(temp_x, temp_y)
i=kneePoints_collected[4000]
temp_x = i
temp_y = Vmax*temp_x / (K*temp_x)
points(temp_x, temp_y)
temp_x
i=kneePoints_collected[400]
temp_x = i
temp_y = Vmax*temp_x / (K*temp_x)
points(temp_x, temp_y)
temp_y
temp_y = Vmax*temp_x / (K+temp_x)
points(temp_x, temp_y)
# Gonna write it out first, then make it into a function
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(PIG_DATE, OUA))
# if the variance is equal to zero, then its a zero-column
#which(unname(apply(inData, 2, var))==0)
throwAway <- which(apply(inData, 2, var)==0)[]
# dropping columns by index
inData = inData[, -throwAway]
rm(throwAway) # to save memory
print("Generating metadata...")
## finding different interesting information on the set
## mean, var, STD, ratio of zeros,
meanData  <- unname(apply(inData, 2, mean))
stdData   <- unname(apply(inData, 2, sd))
varData   <- unname(apply(inData, 2, var))
ratioData <- unname(apply(inData, 2, function(x){length(which(x==0))/length(x)}))
CVData    <- unname(apply(inData, 2, function(x){sd(x)/mean(x)}))
plot(sort(meanData), main = "Mean Data")
plot(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(ratioData), main = "Singleton ratios")
plot(sort(CVData), main = "Relative standard deviation")
# fitting Michaelis-Menten function to data
print("Fitting Michaelis-Menten function...")
time_frame <- seq(from = 1, to = length(ratioData), by = 1)
mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame), start = list(Vm=max(ratioData), K=max(time_frame) / 2))
# parameters estimated including confidence interval
coef(mmModel)
confint(mmModel, level = 0.9)
# defining to estimated parameters
Vmax = coef(mmModel)[[1]]
K    = coef(mmModel)[[2]]
# visualizing the model in relation to ratio Data
plot(sort(ratioData) ~ time_frame, col = "grey")
lines(predict(mmModel) ~ time_frame, lwd = 3, col = "dark red")
# finding local maxima, potentiel knee points
kneePoints_collected <- which(diff(sign(diff(ratioData)))==-2)+1
# finding the linear fit from origo to asymptote
a_linearFit <- max(ratioData) / max(time_frame)
b_linearFit <- min(ratioData) - a_linearFit*min(time_frame)
abline(a = b_linearFit, b=a_linearFit)
# using distance formular on all knee points to line
# distance formula: d = abs(a*x+b-y)/sqrt(a^2+1)
longest_distance  <- 0
longest_x         <- 0
i=kneePoints_collected[400]
for (i in kneePoints_collected) {
temp_x = i
temp_y = Vmax*temp_x / (K+temp_x)
#points(temp_x, temp_y)
dist = abs(a_linearFit*temp_x + b_linearFit-temp_y)/sqrt(a_linearFit^2+1)
if (dist >= longest_distance) {longest_distance = dist; longest_x = temp_x}
}
# defining the cutoff threshold
threshold_ratio <- ratioData[longest_x]
threshold_ratio
abline(h = threshold_ratio)
findEpsi=function(L, minRange=0,maxRange=3, steps=0.1, maxY=200, minP=10) {
plot(0,0, col=0,xlim=c(minRange,maxRange), ylim=c(0,maxY))
legend("topright", legend = c("nClust","nOutliers"), col=1:2, pch=16)
for(i in seq(minRange,maxRange,steps)) {
DB=dbscan::dbscan(L,i,minP)
points(i,length(unique(DB$cluster)), pch=16, col=1)
points(i,length(which(DB$cluster==0)), pch=16,col=2)
}
}
findEpsi(inData)
findEpsi(inData, minRange = 0, maxRange = 1000, steps = 100)
findEpsi(inData, minRange = 0, maxRange = 100000, steps = 10000)
findEpsi(inData, minRange = 30000, maxRange = 60000, steps = 10000,maxY=30)
dbscan::dbscan(inData,40000,10)
dbscan::dbscan(inData,4000,10)
dbscan::dbscan(inData,400,10)
dbscan::dbscan(inData,4000,10)
dbscan::dbscan(inData,20000,10)
dbscan::dbscan(inData,10000,10)
dbscan::dbscan(scale(inData),10000,10)
inDataScale=scale(inData, center = T, scale = T)
View(inDataScale)
findEpsi(inDataScale, minRange = 0, maxRange = 100, steps = 10,maxY=30)
head(colnames(inData))
stringr::str_split_fixed(colnames(inData), pattern = "_",6)
stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6]
paste(stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6],"_")
paste(stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6],collapse = "_")
paste(stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6],sep  = "_")
paste(stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6],sep  = "_",collapse = "_")
apply(stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6],1, paste, collase="_")
apply(stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6],1, paste, collapse="_")
newNames=apply(stringr::str_split_fixed(colnames(inData), pattern = "_",7)[,1:6],1, paste, collapse="_")
length(unique(newNames))
newNames
uniqNames=unique(newNames)
origNames=colnames(inData)
j=uniqNames[1]
grep(j,origNames )
jIndx=grep(j,origNames )
inData[,jIndx]
rowSums(inData[,jIndx]  )
newDat=data.frame()
j=uniqNames[1]
for(j in uniqNames) {
jIndx=grep(j,origNames )
newDat=cbind(newDat,rowSums(inData[,jIndx]))
}
newDat=data.frame(dummy=1:NROW(inData))
j=uniqNames[1]
for(j in uniqNames) {
jIndx=grep(j,origNames )
newDat=cbind(newDat,rowSums(inData[,jIndx]))
}
newDat
jIndx
rowSums(inData[,jIndx])
newDat=data.frame(dummy=1:NROW(inData))
j=uniqNames[1]
for(j in uniqNames) {
jIndx=grep(j,origNames )
if(length(jIndx)>1) {
newDat=cbind(newDat,rowSums(inData[,jIndx]))
} else {
newDat=cbind(newDat,(inData[,jIndx]))
}
}
newDat=newDat[,-1]
colnames(newDat)=uniqNames
# Gonna write it out first, then make it into a function
inData = data
testID  <- inData$PIG_DATE
OUA     <- inData$OUA
inData = subset(inData, select = -c(PIG_DATE, OUA))
# if the variance is equal to zero, then its a zero-column
#which(unname(apply(inData, 2, var))==0)
throwAway <- which(apply(inData, 2, var)==0)[]
# dropping columns by index
inData = inData[, -throwAway]
rm(throwAway) # to save memory
print("Generating metadata...")
## finding different interesting information on the set
## mean, var, STD, ratio of zeros,
meanData  <- unname(apply(inData, 2, mean))
stdData   <- unname(apply(inData, 2, sd))
varData   <- unname(apply(inData, 2, var))
ratioData <- unname(apply(inData, 2, function(x){length(which(x==0))/length(x)}))
CVData    <- unname(apply(inData, 2, function(x){sd(x)/mean(x)}))
plot(sort(meanData), main = "Mean Data")
plot(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(ratioData), main = "Singleton ratios")
plot(sort(CVData), main = "Relative standard deviation")
# fitting Michaelis-Menten function to data
print("Fitting Michaelis-Menten function...")
time_frame <- seq(from = 1, to = length(ratioData), by = 1)
mmModel <- nls(sort(ratioData) ~ Vm*time_frame/(K+time_frame), start = list(Vm=max(ratioData), K=max(time_frame) / 2))
# parameters estimated including confidence interval
coef(mmModel)
confint(mmModel, level = 0.9)
# defining to estimated parameters
Vmax = coef(mmModel)[[1]]
K    = coef(mmModel)[[2]]
# visualizing the model in relation to ratio Data
plot(sort(ratioData) ~ time_frame, col = "grey")
lines(predict(mmModel) ~ time_frame, lwd = 3, col = "dark red")
# finding local maxima, potentiel knee points
kneePoints_collected <- which(diff(sign(diff(ratioData)))==-2)+1
# finding the linear fit from origo to asymptote
a_linearFit <- max(ratioData) / max(time_frame)
b_linearFit <- min(ratioData) - a_linearFit*min(time_frame)
max_x = which(sort(ratioData)>=max(ratioData)*0.97)[1]
max_y = Vmax*max_x / (K+max_x)
a_linearFit <- (max_y - min(ratioData)) / (max_x-min(time_frame))
b_linearFit <- min(ratioData) - a_linearFit*min(time_frame)
abline(a = b_linearFit, b=a_linearFit)
# using distance formular on all knee points to line
# distance formula: d = abs(a*x+b-y)/sqrt(a^2+1)
longest_distance  <- 0
longest_x         <- 0
#i=kneePoints_collected[400]
for (i in which(kneePoints_collected<=max_x)) {
temp_x = i
temp_y = Vmax*temp_x / (K+temp_x)
#points(temp_x, temp_y)
dist = abs(a_linearFit*temp_x + b_linearFit-temp_y)/sqrt(a_linearFit^2+1)
if (dist >= longest_distance) {longest_distance = dist; longest_x = temp_x}
}
# defining the cutoff threshold
threshold_ratio <- Vmax*longest_x / (K+longest_x)
points(longest_x, threshold_ratio)
abline(h = threshold_ratio)
# if the ratioData is above the found cutoff, it is to be removed
keepIn <- which(ratioData <= threshold_ratio)
# dropping columns by index
sprintf("Filtering out data with zero-ratio above %f...", threshold_ratio)
inData = inData[, keepIn]
rm(keepIn) # to save memory
meanData  <- unname(apply(inData, 2, mean))
stdData   <- unname(apply(inData, 2, sd))
varData   <- unname(apply(inData, 2, var))
ratioData <- unname(apply(inData, 2, function(x){length(which(x==0))/length(x)}))
CVData    <- unname(apply(inData, 2, function(x){sd(x)/mean(x)}))
plot(sort(meanData), main = "Mean Data")
plot(sort(stdData), main = "Standard Variations")
plot(sort(varData), main = "Variance")
plot(sort(ratioData), main = "Singleton ratios")
plot(sort(CVData), main = "Relative standard deviation")
inData = cbind(testID, OUA, inData)
outData = inData
data_16s  <- read.table("Testdata/allData_16S_cleaned.txt")
data_qpcr <- read.table("Testdata/allData_qPCR_cleaned.txt")
# next, include only testID (PIG_DATE), OUA and the results of the analyses
pure_data_16s   <- subset(data_16s, select = -c(PIG, DATE, WEANING_TIME, GROUP, Newlytreated,
WEEK, SAMPLEWEEK, Florkem, Metacam, Zactran,
Antibiotic, Treatment_group, Treatment_date, CorrectedGroup,
PIG.1, DATE.1, OUA.1, PIG_DATE.1, OriginalNAME))
pure_data_qpcr  <- subset(data_qpcr, select = -c(PIG, DATE, WEANING_TIME, GROUP, Newlytreated,
WEEK, SAMPLEWEEK, Florkem, Metacam, Zactran,
Antibiotic, Treatment_group, Treatment_date, CorrectedGroup, sample))
# extract two arrays of testIDs, and find which are common between them both
testID_16s  <- pure_data_16s$PIG_DATE
testID_qpcr <- pure_data_qpcr$PIG_DATE
common_IDs  <- intersect(testID_16s, testID_qpcr)
# only keep relevant testIDs
pure_data_16s   = pure_data_16s[data_16s$PIG_DATE %in% common_IDs, ]
pure_data_qpcr  = pure_data_qpcr[data_qpcr$PIG_DATE %in% common_IDs, ]
# sort the datasets based testID, append whilst removing 1 edition of testID and OUA
pure_data_16s   = pure_data_16s[order(pure_data_16s$PIG_DATE), ]
pure_data_qpcr  = pure_data_qpcr[order(pure_data_qpcr$PIG_DATE), ]
pure_data_qpcr  = subset(pure_data_qpcr, select = -c(PIG_DATE, OUA))
# moving up in taxonomy for the 16s data, going from species to genus
origNames <- colnames(data_16s)
newNames <- apply(stringr::str_split_fixed(string = origNames, pattern = "_",8)[,1:6],1, paste, collapse="_")
length(unique(newNames))
uniqNames=unique(newNames)
